{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Item and User based Collaborative Filtering ",
      "provenance": [],
      "collapsed_sections": [
        "lfAF7gZU3LkW"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyG45Qk3qQLS"
      },
      "source": [
        "\n",
        " Item and User based Collaborative Filtering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6tDF1HQSHD"
      },
      "source": [
        "## Introduction:\n",
        "\n",
        "**Collaborative filtering (CF)**: \n",
        "\n",
        "Collaborative filtering is a technique used by recommender systems. The most common filter being used is user-based and item based.\n",
        "\n",
        "**User based collaborative filtering (UBCF)** : \n",
        "\n",
        "Find similar users to me and recommend what they liked.\n",
        "\n",
        "**Item based collaborative filtering (IBCF)** : \n",
        "\n",
        "Find similar items to those that I have previously liked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cfWKFfRZmm3"
      },
      "source": [
        "## Data Description:\n",
        "This is a dataset which contains 100k rating informations which having 943 users and 1682 movies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFMJSCNc2ibL"
      },
      "source": [
        "### Upload Data and Get An Insight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbohV_gzYpZv"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload MovieLens 100k Dataset\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13yJLtXP2hNG",
        "outputId": "7ac0b88f-c4d2-475a-f9ad-7b785a733e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import pandas\n",
        "\n",
        "df = pandas.read_csv('ml-100k.data',header=None, sep='\\t',names=[\"user_id\", \"movie_id\", \"rating\",\"timestamp\"])\n",
        "\n",
        "# Get the Number of Users and Items\n",
        "n_users, n_items = df['user_id'].unique().shape[0], df['movie_id'].unique().shape[0]\n",
        "print(n_users, n_items)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "943 1682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  movie_id  rating  timestamp\n",
              "0      196       242       3  881250949\n",
              "1      186       302       3  891717742\n",
              "2       22       377       1  878887116\n",
              "3      244        51       2  880606923\n",
              "4      166       346       1  886397596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Bdmc3O-lzU"
      },
      "source": [
        "The first column(with bold) is the row number, the second column is the user id, the third column is the movie id, the fourth column is the rating of a specific user to a specific movie, in this tutorial we didn't use timestamp for calculation, the only thing we are using is the user_id, movie_id and the rating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bOWmXT7flD5"
      },
      "source": [
        "## Random Recommendation\n",
        "\n",
        "Algorithm predicting a random rating based on the distribution of the training set, which is assumed to be normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5icxJbxg2Hs"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload utils.py\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPe84b3Thjpq"
      },
      "source": [
        "### Use the Surprise Library\n",
        "\n",
        "[SURPRISE Libraray](http://surpriselib.com/)\n",
        "\n",
        "Surprise is a Python scikit building and analyzing recommender systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwwuJa8eg7wr",
        "outputId": "d4daa3ed-eb3b-4bdc-dd1e-70c85366b0b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Install the scikit-surprise library\n",
        "!pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.16.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.13.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCtKEZnwfn6u",
        "outputId": "3ce881f7-c943-4a25-a313-ae8503bc309d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "from utils import *\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import NormalPredictor\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "\n",
        "# Load the data\n",
        "data, n_users, n_items = spr_loadData('ml-100k.data')\n",
        "\n",
        "# Select Algorithm KNNWithMeans and Run It\n",
        "algo = NormalPredictor()\n",
        "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    1.5263  1.5172  1.5246  1.5341  1.5158  1.5236  0.0066  \n",
            "Fit time          0.14    0.17    0.17    0.17    0.16    0.16    0.01    \n",
            "Test time         0.25    0.13    0.23    0.13    0.13    0.18    0.06    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (0.1415097713470459,\n",
              "  0.16597723960876465,\n",
              "  0.1653599739074707,\n",
              "  0.16808438301086426,\n",
              "  0.16346001625061035),\n",
              " 'test_rmse': array([1.52630024, 1.51715398, 1.52460949, 1.5340634 , 1.51579938]),\n",
              " 'test_time': (0.25188350677490234,\n",
              "  0.1308126449584961,\n",
              "  0.23431658744812012,\n",
              "  0.13154888153076172,\n",
              "  0.1317145824432373)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bqjkGKwQSHW"
      },
      "source": [
        "## User-based Neighborhood method:\n",
        "\n",
        "Imagine that we want to recommend a movie to our friend Daven. We could assume that similar people will have similar taste. Suppose that me and Daven have seen the same movies, and we rated them all almost identically. But Daven hasn’t seen *'Infinity war'* but I did. \n",
        "\n",
        "If I love that movie, it sounds logical to think that he will too. With that, we have created an artificial rating based on our similarity.\n",
        "\n",
        "In here we are using User-based Nearest Neighbor algorithm. \n",
        "This algorithm needs two tasks:\n",
        "\n",
        "1. Find the nearest neighbors to the user A, using a similarity function *sim* to measure the distance between each pair of users.\n",
        "2.Predict the rating that user A will give to all items the neighbors have consumed but A has not. We Look for the item j with the best predicted rating.\n",
        "\n",
        "In other words, we are creating a User-Item Matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbEmbrQVVDYi"
      },
      "source": [
        "## Use the Surprise Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLYiGrXzVQKB",
        "outputId": "34a11471-2611-4510-a2e2-ee3fe9b80e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "from utils import *\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import KNNWithMeans\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "\n",
        "# Load the data\n",
        "data, n_users, n_items = spr_loadData('ml-100k.data')\n",
        "\n",
        "# Select Algorithm KNNWithMeans and Run It\n",
        "sim_options = {'name': 'cosine',\n",
        "               'user_based': True  # compute similarities between users\n",
        "              }\n",
        "algo = KNNWithMeans(k=n_users,sim_options=sim_options)\n",
        "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating RMSE of algorithm KNNWithMeans on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9626  0.9581  0.9547  0.9607  0.9659  0.9604  0.0038  \n",
            "Fit time          1.19    1.21    1.24    1.23    1.23    1.22    0.02    \n",
            "Test time         5.67    5.54    5.55    5.49    5.55    5.56    0.06    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (1.1923482418060303,\n",
              "  1.2132914066314697,\n",
              "  1.2415211200714111,\n",
              "  1.2330732345581055,\n",
              "  1.2282624244689941),\n",
              " 'test_rmse': array([0.96257679, 0.95814613, 0.95467731, 0.96066776, 0.96594893]),\n",
              " 'test_time': (5.66754412651062,\n",
              "  5.540053606033325,\n",
              "  5.546735763549805,\n",
              "  5.488779544830322,\n",
              "  5.54682731628418)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK91SJA7YX1p"
      },
      "source": [
        "## User-based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOLi-WhBT60x"
      },
      "source": [
        "### Import and Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVkFRu1IR_Da"
      },
      "source": [
        "#import libraries and helper functions\n",
        "from utils import *\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import heapq\n",
        "import warnings; warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPuhT6tQSFRe"
      },
      "source": [
        "### Cosine similarity\n",
        "\n",
        "This is a example of *sim* function, there are several different method to get the degree of similarity. In here we used a function *cosine_similarity* from sklearn.metrics.pairwise. Read more about the function usage in [here.](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aw1pLv1WWTz"
      },
      "source": [
        "def cosSimilarityUser(data):\n",
        "    # Calculate the Cosine Similarity Matrix\n",
        "    user_similarity = cosine_similarity(data)\n",
        "    \n",
        "    # Preview the Similarity Matrix\n",
        "    print(\"Similarity Matrix Sample\")\n",
        "    print(user_similarity[:5, :5])\n",
        "    print(\"Similarity Matrix Dimension\")\n",
        "    print(np.shape(user_similarity))\n",
        "    print(\"=\" * 120)\n",
        "    \n",
        "    return user_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDpRtvO6W3wS"
      },
      "source": [
        "### Prediction formula\n",
        "Recall from the lecture, the user based collaborative predict function is \n",
        "\n",
        "![alt text](https://i.ibb.co/9YsmHNp/Screenshot-2019-05-28-15-51-36.png)\n",
        "\n",
        "\n",
        "Below is a realization of the function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EffC9ZfNW1yB"
      },
      "source": [
        "def predictUser(ratings, similarity, num_items):\n",
        "    # The Average Rating Values for Each User\n",
        "    mean_user_rating = np.repeat(np.array([ratings.mean(axis=1)]), num_items, axis=0).T\n",
        "\n",
        "    # The Difference Between Each Rating Value and The Average Value\n",
        "    ratings_diff = ratings - mean_user_rating\n",
        "\n",
        "    # Calculate the Predicted Score\n",
        "    pred = mean_user_rating + \\\n",
        "           np.dot(similarity, ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
        "    \n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6CLvssqXRK1"
      },
      "source": [
        "### Recommend Items For A Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yabD8xg_XSBi"
      },
      "source": [
        "def recItemsForOneUser(pred_array, train_array, user, num_rec):\n",
        "    # Change Training Arrary Into Sparse Matrix\n",
        "    train_matrix = sp.csr_matrix(train_array)\n",
        "\n",
        "    # Get the Item IDs in the Training Data For the Specified User\n",
        "    train_items_for_user = train_matrix.getrow(user).nonzero()[1]\n",
        "\n",
        "    # Create A Dictionary with Key-Value Pairs as ItemID-PredictedValue Pair\n",
        "    pred_dict_for_user = dict(zip(np.arange(train_matrix.shape[1]), pred_array[user]))\n",
        "\n",
        "    # Remove the Key-Value Pairs used in Training\n",
        "    for iid in train_items_for_user:\n",
        "        pred_dict_for_user.pop(iid)\n",
        "\n",
        "    # Select the Top-N Items in The Sorted List\n",
        "    rec_list_for_user = heapq.nlargest(num_rec, pred_dict_for_user.items(), key=lambda tup: tup[1])\n",
        "\n",
        "    # Get the Item ID List From the Top-N Tuples\n",
        "    rec_item_list = [tup[0] for tup in rec_list_for_user]\n",
        "    return rec_item_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3p3Sn4vYd0d"
      },
      "source": [
        "### Metrics Calculation Precision And Recall\n",
        "\n",
        "**Precision** measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\n",
        "\n",
        "**Recall** measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoWgviIpYja0"
      },
      "source": [
        "def Precision_and_Recall(pred_item_list, test_item_list):\n",
        "    # Calculate the Number of Occurrences of Testing Item IDs in the Prediction Item ID List\n",
        "    sum_relevant_item = 0\n",
        "    for item in test_item_list:\n",
        "        if item in pred_item_list:\n",
        "            sum_relevant_item += 1\n",
        "\n",
        "    # Calculate the Precision and Recall Value\n",
        "    precision = sum_relevant_item / len(pred_item_list)\n",
        "    recall = sum_relevant_item / len(test_item_list)\n",
        "\n",
        "    return precision, recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euqlA1-XpwHm"
      },
      "source": [
        "### Metrics Calculation Average Precision And Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FouidY9Pp8qZ"
      },
      "source": [
        "def calMetrics(train_array, test_array, pred_array, at_K):\n",
        "    # Get All the User IDs in Test Dataset\n",
        "    test_matrix = sp.coo_matrix(test_array)\n",
        "    test_users = test_matrix.row\n",
        "    test_matrix = test_matrix.tocsr()\n",
        "\n",
        "    # List to Store the Precision/Recall Value for Each User\n",
        "    precision_u_at_K = []\n",
        "    recall_u_at_K = []\n",
        "\n",
        "    # Loop for Each User\n",
        "    for u in test_users:\n",
        "        # Get the Recommendation List for the User in Consideration\n",
        "        rec_list_u = recItemsForOneUser(pred_array, train_array, u, at_K)\n",
        "\n",
        "        # Generate an Item ID List For Testing\n",
        "        item_list_u = test_matrix.getrow(u).nonzero()[1]\n",
        "\n",
        "        # Calculate the Precision and Recall Value for this User\n",
        "        precision_u, recall_u = Precision_and_Recall(rec_list_u, item_list_u)\n",
        "\n",
        "        # Save the Precision/Recall Values\n",
        "        precision_u_at_K.append(precision_u)\n",
        "        recall_u_at_K.append(recall_u)\n",
        "\n",
        "    # Calculate the Average Precision/Recall Values Over All Users\n",
        "    print(\"Precision@\"+str(at_K)+\": \"+str(np.mean(precision_u_at_K)))\n",
        "    print(\"Recall@\"+str(at_K)+\": \"+str(np.mean(recall_u_at_K)))\n",
        "    print(\"=\" * 120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AncJgHVJp_cv"
      },
      "source": [
        "### User-based kNN Recommendation Main Program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo-YSdFDqFzz",
        "outputId": "f2e556dc-6764-4ab6-cd08-94a42f0050cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load Data\n",
        "    train, test, num_users, num_items, uid_min, iid_min = loadData(test_size=0.2)\n",
        "    train_array, test_array = train.toarray(), test.toarray()\n",
        "    \n",
        "    # Similarity And Prediction Matrices (User)\n",
        "    similarity_user_array = cosSimilarityUser(train_array)\n",
        "    pred_user_array = predictUser(train_array, similarity_user_array, num_items)\n",
        "\n",
        "    # Recommendation\n",
        "    rec_list = recItemsForOneUser(pred_user_array, train_array, 257, 10)\n",
        "    print(\"The Recommendation List for User Is: \" + str(rec_list+iid_min))\n",
        "    print(\"=\" * 120)\n",
        "    \n",
        "    # Metrics Calculation\n",
        "    calMetrics(train_array, test_array, pred_user_array, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preview:\n",
            "   uid  iid  ratings       time\n",
            "0  196  242        3  881250949\n",
            "1  186  302        3  891717742\n",
            "2   22  377        1  878887116\n",
            "3  244   51        2  880606923\n",
            "4  166  346        1  886397596\n",
            "========================================================================================================================\n",
            "Number of Users: 943\n",
            "Number of Items: 1682\n",
            "========================================================================================================================\n",
            "Sample Data: [[5 3 4 ... 0 0 0]]\n",
            "========================================================================================================================\n",
            "Similarity Matrix Sample\n",
            "[[1.         0.16359537 0.03365039 0.07323055 0.30757548]\n",
            " [0.16359537 1.         0.08520491 0.16757297 0.07164769]\n",
            " [0.03365039 0.08520491 1.         0.19338712 0.02781491]\n",
            " [0.07323055 0.16757297 0.19338712 1.         0.03761586]\n",
            " [0.30757548 0.07164769 0.02781491 0.03761586 1.        ]]\n",
            "Similarity Matrix Dimension\n",
            "(943, 943)\n",
            "========================================================================================================================\n",
            "The Recommendation List for User Is: [313 288 286 302  50 269 748 333 181 245]\n",
            "========================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfAF7gZU3LkW"
      },
      "source": [
        "## Quiz Question 1: \n",
        "\n",
        "There are several popular similarity functions we can use in compute the degree of similarity between users, in here we used Cosine similarity, can you implement a Euclidean method?\n",
        "\n",
        "(This is the formula of euclidean distance.)\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*n6kmkzjKVTOWeXDxsx2daQ.png)\n",
        "\n",
        "(This is the[ sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html) might be helpful for you.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFpA8rRh6dKn"
      },
      "source": [
        "def EuclideanRec(train_data):\n",
        "    #write your code in here \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIbWb5LF7mtn"
      },
      "source": [
        "#You don't have to change this\n",
        "if __name__ == '__main__':\n",
        "    # Load Data\n",
        "    train, test, num_users, num_items, uid_min, iid_min = loadData(test_size=0.2)\n",
        "    train_array, test_array = train.toarray(), test.toarray()\n",
        "    \n",
        "    # Similarity And Prediction Matrices (User)\n",
        "    similarity_user_array = EuclideanRec(train_array)\n",
        "    pred_user_array = predictUser(train_array, similarity_user_array, num_items)\n",
        "\n",
        "    # Recommendation\n",
        "    rec_list = recItemsForOneUser(pred_user_array, train_array, 257, 10)\n",
        "    print(\"The Recommendation List for User Is: \" + str(rec_list+iid_min))\n",
        "    print(\"=\" * 120)\n",
        "    \n",
        "    # Metrics Calculation\n",
        "    calMetrics(train_array, test_array, pred_user_array, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggXH701Wt8KH"
      },
      "source": [
        "## Item-based Collaborative Filtering:\n",
        "\n",
        "Imagine now for Daven, instead of focusing on his friends, we could focus on what items from all the options are more similar to what we know he enjoys. This new focus is known as Item-Based Collaborative Filtering (IB-CF).\n",
        "\n",
        "The difference between User-based and this method is that, in this case, we directly pre-calculate the similarity between the co-rated items, skipping K-neighborhood search.\n",
        "\n",
        "This algorithm needs two tasks:\n",
        "\n",
        "1. Calculate similarity among the items, such as cosine-based similarity.\n",
        "2.Calculation of Prediction in weighted sum method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W89iJPW_Y9vh"
      },
      "source": [
        "## Use the Surprise Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-6CMCLwY8uW"
      },
      "source": [
        "from utils import *\n",
        "from surprise import KNNWithMeans\n",
        "from surprise.model_selection import cross_validate\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "\n",
        "# Load the data\n",
        "data, n_users, n_items = spr_loadData('ml-100k.data')\n",
        "\n",
        "# Select Algorithm KNNWithMeans and Run It\n",
        "sim_options = {'name': 'cosine',\n",
        "               'user_based': False  # compute similarities between items\n",
        "              }\n",
        "algo = KNNWithMeans(k=n_items,sim_options=sim_options)\n",
        "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29CqE42O2NA-"
      },
      "source": [
        "### Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFxtd7c04iU"
      },
      "source": [
        "def cosSimilarityItem(data):\n",
        "    item_similarity = cosine_similarity(data.T)\n",
        "    return item_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnSoRNkz1Fx6"
      },
      "source": [
        "### Prediction formula\n",
        "\n",
        "refer to lecture notes, item based collaborative filtering.\n",
        "\n",
        "![alt text](https://cdn-images-1.medium.com/max/800/1*Euu92KfKBZJRwXVyqVkH9w.jpeg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX_K4aix1GL9"
      },
      "source": [
        "def predictItem(ratings, similarity, num_users):\n",
        "    # The Average Rating Values for Each Item\n",
        "    mean_item_rating = np.repeat(np.array([ratings.mean(axis=0)]), num_users, axis=0)\n",
        "\n",
        "    # The Difference Between Each Rating Value and The Average Value\n",
        "    ratings_diff = ratings - mean_item_rating\n",
        "\n",
        "    # Calculate the Predicted Score\n",
        "    pred = mean_item_rating + \\\n",
        "           np.dot(ratings_diff, similarity) / np.abs(similarity).sum(axis=1)\n",
        "\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWrmUivl1fWS"
      },
      "source": [
        "\n",
        "### Item kNN Main Program\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISRl8o4XCc4J"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load Data\n",
        "    train, test, num_users, num_items, uid_min, iid_min = loadData(test_size=0.2)\n",
        "    train_array, test_array = train.toarray(), test.toarray()\n",
        "\n",
        "    # Similarity And Prediction Matrices (Item)\n",
        "    similarity_item_array = cosSimilarityItem(train_array)\n",
        "    pred_item_array = predictItem(train_array, similarity_item_array, num_users)\n",
        "\n",
        "    # Recommendation\n",
        "    rec_list = recItemsForOneUser(pred_item_array, train_array, 257, 10)\n",
        "    print(\"The Recommendation List for User Is: \" + str(rec_list+iid_min))\n",
        "    print(\"=\" * 120)\n",
        "    \n",
        "    # Metrics Calculation\n",
        "    calMetrics(train_array, test_array, pred_item_array, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q0fAwseAyoM"
      },
      "source": [
        "## Quiz Question 2: \n",
        "In the tutorial we compute the precison and recall metrics. These metrics are for ranking tasks.\n",
        "For the prediction task, we usually use the Root-Mean-Square (RMS) metrics.\n",
        "\n",
        "Can you change the above code to calculate the RMS value between the prediction ratings and ground-truth (testing) ratings?\n",
        "\n",
        "![RMS](https://www.includehelp.com/ml-ai/Images/rmse-1.jpg)\n",
        "\n",
        "\n",
        "You can refer to the sklearn package for RMSE calculation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJfBUEgBBQww"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def RMS(pred_rating_array, test_rating_array):\n",
        "    # Assume you have the inputs: the predicted rating array and the testing rating array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pFwNfvnw-Mn"
      },
      "source": [
        "### Modify the following function to calculate the RMS metrics of the recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W38g0zi9s7qk"
      },
      "source": [
        "def calMetrics(pred_array, test_array):\n",
        "    # Filter the Original Prediction Array with Only Testing Items Left\n",
        "    \n",
        "    # Calculate RMS value\n",
        "    RMS_Val = RMS(pred_rating_array, test_array)\n",
        "    \n",
        "    # Print it Out\n",
        "    print(\"RMS: \"+str(RMS_Val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szwe-M8nxjZU"
      },
      "source": [
        "### Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk3b6iiEsz6E"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load Data\n",
        "    train, test, num_users, num_items, uid_min, iid_min = loadData(test_size=0.2)\n",
        "    train_array, test_array = train.toarray(), test.toarray()\n",
        "    \n",
        "    # Similarity And Prediction Matrices (User)\n",
        "    similarity_user_array = cosSimilarityUser(train_array)\n",
        "    pred_user_array = predictUser(train_array, similarity_user_array, num_items)\n",
        "\n",
        "    # RMS\n",
        "    calMetrics(pred_user_array, test_array)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}